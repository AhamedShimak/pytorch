{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVrSw/pkfBU8/F8+a0NyQ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhamedShimak/pytorch/blob/main/computer_vision_cnn_code_along.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT AND MY DEFINED FUNCTIONS"
      ],
      "metadata": {
        "id": "n7Gn_JhaG7dY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "Glqkeh5CHfl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fQb72sHRBxT6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###My functions"
      ],
      "metadata": {
        "id": "8zKnh3Aga-W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def details(tensor):\n",
        "  print(\"\")\n",
        "  print(\"Shape: \",tensor.shape)\n",
        "  print(\"Dimentions: \",tensor.ndim)\n",
        "  print(\"###########\")\n",
        "  print(tensor)\n",
        "  print(\"###########\")\n",
        "  print(\"Tensor Data type: \",tensor.dtype)\n",
        "  print(\"Device: \",tensor.device)\n",
        "  print(\"\")\n",
        "\n",
        "def details_plot(train_data, \n",
        "                     train_labels, \n",
        "                     test_data, \n",
        "                     test_labels,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "  \n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});\n",
        "\n",
        "def details_loss_curve(epochs,train_loss_track,test_loss_track):\n",
        "  #loss curve\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.title(\"Loss curve\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.plot(epochs,train_loss_track,label=\"Train loss\")\n",
        "  plt.plot(epochs,test_loss_track,label=\"Test loss\")\n",
        "  plt.legend(prop={\"size\": 14})\n",
        "\n",
        "import torch\n",
        "def details(tensor):\n",
        "  print(\"\")\n",
        "  print(\"Shape: \",tensor.shape)\n",
        "  print(\"Dimentions: \",tensor.ndim)\n",
        "  print(\"###########\")\n",
        "  print(tensor)\n",
        "  print(\"###########\")\n",
        "  print(\"Tensor Data type: \",tensor.dtype)\n",
        "  print(\"Device: \",tensor.device)\n",
        "  print(\"\")\n",
        "\n",
        "def details_plot(train_data, \n",
        "                     train_labels, \n",
        "                     test_data, \n",
        "                     test_labels,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "  \n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});\n",
        "\n",
        "\n",
        "\n",
        "def accu(y_pred,y_test):\n",
        "  correct=torch.eq(y_pred,y_test).sum().item()\n",
        "  accuracy=(correct/len(y_test))*100\n",
        "  return accuracy\n",
        "\n",
        "def details_plot_scatter(x_train, x_test, y_train, y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.scatter(x_train[:,0],x_train[:,1],c=y_train,cmap=plt.cm.BrBG, s=4, label=\"Training data\")\n",
        "  plt.scatter(x_test[:,0],x_test[:,1],c=y_test, s=60, label=\"Test data\")\n",
        "  plt.legend(prop={\"size\": 14});\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(x_test[:,0],x_test[:,1],c=predictions, s=20, label=\"Prediction\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "aYgYxCDHbBTO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GPU"
      ],
      "metadata": {
        "id": "sMRYymjLIGWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n",
        "#setup device agnostic code\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nw_wfJXIIs0",
        "outputId": "8267a03a-ffd8-4fbc-e8ad-a95eace48b7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 26 10:26:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DATA PROCESS \n"
      ],
      "metadata": {
        "id": "ptqUbYftO67F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ex- tensor data-> x_train,y_train,x_test,y_test\n"
      ],
      "metadata": {
        "id": "oMw_nOmGLh5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create data\n",
        "\n",
        "train=datasets.FashionMNIST(\n",
        "    root=\"Data\",\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "test=datasets.FashionMNIST(\n",
        "    root=\"Data_test\",\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "#weight and bias\n",
        "\n",
        "  #######to prevent mat multiplication error   .unsqueeze(dim=1)\n"
      ],
      "metadata": {
        "id": "Khi062A2O-_5",
        "outputId": "9088ff69-1343-4638-e724-0ad6ec1ca251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to Data_test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 8415442.50it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data_test/FashionMNIST/raw/train-images-idx3-ubyte.gz to Data_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to Data_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 145404.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data_test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to Data_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to Data_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2680481.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data_test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to Data_test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to Data_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 19470042.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data_test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to Data_test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "details(train.data[0])"
      ],
      "metadata": {
        "id": "eeO0hiCMI6l5",
        "outputId": "6ce6bd21-1910-4b78-fb4b-df170e068ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape:  torch.Size([28, 28])\n",
            "Dimentions:  2\n",
            "###########\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
            "           0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
            "          36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
            "         102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
            "         207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
            "         232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
            "         225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
            "         228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
            "         220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
            "         222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
            "         228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
            "        [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
            "         217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
            "        [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
            "         213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
            "        [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
            "         200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
            "        [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
            "         245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
            "        [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
            "         150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
            "        [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
            "          65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
            "        [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
            "         240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
            "        [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
            "         220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
            "        [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
            "         200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
            "        [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
            "         193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
            "        [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
            "         220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
            "       dtype=torch.uint8)\n",
            "###########\n",
            "Tensor Data type:  torch.uint8\n",
            "Device:  cpu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZ-1ksuRLJ-B"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train/test split\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "for i in range(9):\n",
        "  img,label=train[i]\n",
        "  plt.figure(figsize=(8,8)).add_subplot(3,3,i+1)\n",
        "  plt.imshow(img.squeeze())\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis(\"off\")\n",
        "  "
      ],
      "metadata": {
        "id": "SGZ3v5LHPG_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_loader\n",
        "torch.manual_seed(23)\n",
        "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test, batch_size=32, shuffle=False)\n",
        "\n",
        "len(train_dataloader),len(test_dataloader)"
      ],
      "metadata": {
        "id": "Ju3JoT5WP-V7",
        "outputId": "17d513c9-9c0e-4843-911f-83ea5d0e3773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_b_sample,y_train_b_sample=next(iter(train_dataloader))\n",
        "details(x_train_b_sample),details(y_train_b_sample)\n",
        "\n",
        "plt.imshow(x_train_b_sample[0].squeeze())\n",
        "plt.title(labels_map[y_train_b_sample[0].item()])"
      ],
      "metadata": {
        "id": "lmmYFPxjPdqx",
        "outputId": "93c276a3-bbc1-4ab5-e48b-63382a2dfe9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape:  torch.Size([32, 1, 28, 28])\n",
            "Dimentions:  4\n",
            "###########\n",
            "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.1216,  ..., 0.7804, 0.4196, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0275,  ..., 0.3255, 0.0549, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0431, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.7843, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0667, 0.5255, 0.5922,  ..., 0.1098, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.5608, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
            "###########\n",
            "Tensor Data type:  torch.float32\n",
            "Device:  cpu\n",
            "\n",
            "\n",
            "Shape:  torch.Size([32])\n",
            "Dimentions:  1\n",
            "###########\n",
            "tensor([6, 2, 3, 7, 8, 6, 5, 8, 7, 2, 8, 4, 7, 6, 6, 0, 3, 5, 5, 2, 4, 4, 6, 4,\n",
            "        3, 5, 8, 8, 1, 9, 0, 3])\n",
            "###########\n",
            "Tensor Data type:  torch.int64\n",
            "Device:  cpu\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Shirt')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BUILDING THE MODEL\n"
      ],
      "metadata": {
        "id": "Tto_QOOaQS7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tips\n",
        "1. torch.nn.find_suitable_loss\n",
        "2. torch.nn.Paramenter\n",
        "3. torch.nn.Module this is base class\n",
        "4. torch.optim - optimizer"
      ],
      "metadata": {
        "id": "Zxa0ngYiLY52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#flattern layer\n",
        "details(x_train_b_sample)\n",
        "flattern=nn.Flatten()\n",
        "details(flattern(x_train_b_sample))"
      ],
      "metadata": {
        "id": "yBTKGQGBVsby",
        "outputId": "c6628c9f-a234-4ac3-ede5-d08364f8455f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape:  torch.Size([32, 1, 28, 28])\n",
            "Dimentions:  4\n",
            "###########\n",
            "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.1216,  ..., 0.7804, 0.4196, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0275,  ..., 0.3255, 0.0549, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0431, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.7843, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0667, 0.5255, 0.5922,  ..., 0.1098, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.5608, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
            "###########\n",
            "Tensor Data type:  torch.float32\n",
            "Device:  cpu\n",
            "\n",
            "\n",
            "Shape:  torch.Size([32, 784])\n",
            "Dimentions:  2\n",
            "###########\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "###########\n",
            "Tensor Data type:  torch.float32\n",
            "Device:  cpu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "class fashion_model(nn.Module):\n",
        "  def __init__(self,in_,out_):\n",
        "    super().__init__()\n",
        "    #model_structer\n",
        "    self.layer_stack=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32,out_)\n",
        "    )\n",
        "  def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "\n",
        "\n",
        "#discription of model\n",
        "model=fashion_model(in_=784,out_=10)\n",
        "model.state_dict()"
      ],
      "metadata": {
        "id": "fchfssqDQLCG",
        "outputId": "0c77c869-b496-4277-ca29-3a18f8297fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_stack.2.weight',\n",
              "              tensor([[ 2.1769e-02,  3.4543e-02, -5.3349e-03,  ..., -4.3010e-03,\n",
              "                       -5.1994e-03,  1.9498e-02],\n",
              "                      [ 2.7555e-03,  1.8953e-02,  1.8364e-02,  ..., -3.4814e-02,\n",
              "                        2.9839e-04, -2.0705e-03],\n",
              "                      [-1.9902e-02, -1.0201e-02,  1.1757e-02,  ..., -1.8356e-02,\n",
              "                       -1.1180e-02, -4.0898e-03],\n",
              "                      ...,\n",
              "                      [ 2.6377e-02,  3.5056e-02, -3.1157e-02,  ..., -8.6397e-03,\n",
              "                       -1.2581e-02,  7.1074e-04],\n",
              "                      [ 2.9415e-02, -3.3938e-02,  4.4724e-03,  ...,  2.8709e-02,\n",
              "                       -2.2332e-02, -2.9270e-02],\n",
              "                      [-1.6403e-02,  4.0611e-03, -1.9836e-02,  ...,  1.0308e-02,\n",
              "                       -1.5280e-05,  2.9566e-02]])),\n",
              "             ('layer_stack.2.bias',\n",
              "              tensor([-0.0111,  0.0294, -0.0239,  0.0159,  0.0105, -0.0258,  0.0264,  0.0027,\n",
              "                      -0.0040,  0.0101,  0.0022, -0.0354, -0.0153,  0.0197, -0.0346, -0.0198,\n",
              "                       0.0006, -0.0217, -0.0356, -0.0336,  0.0245,  0.0024,  0.0248, -0.0287,\n",
              "                       0.0335, -0.0120,  0.0351,  0.0022, -0.0172,  0.0347, -0.0073, -0.0356,\n",
              "                      -0.0095, -0.0037, -0.0097, -0.0119,  0.0062, -0.0039, -0.0138,  0.0032,\n",
              "                      -0.0154,  0.0053,  0.0268,  0.0260,  0.0094,  0.0258,  0.0188, -0.0164,\n",
              "                       0.0197,  0.0313, -0.0346, -0.0065,  0.0046,  0.0291, -0.0034,  0.0344,\n",
              "                       0.0247,  0.0215,  0.0199,  0.0032,  0.0044, -0.0353,  0.0086, -0.0290,\n",
              "                      -0.0198, -0.0129,  0.0007,  0.0347, -0.0171,  0.0296, -0.0345,  0.0301,\n",
              "                      -0.0350,  0.0204,  0.0119, -0.0350, -0.0237,  0.0019,  0.0339,  0.0281,\n",
              "                      -0.0010,  0.0111,  0.0202,  0.0206,  0.0265, -0.0107,  0.0161, -0.0347,\n",
              "                       0.0103, -0.0053, -0.0004, -0.0049,  0.0267,  0.0061,  0.0250,  0.0224,\n",
              "                       0.0214, -0.0006,  0.0183, -0.0091, -0.0161, -0.0097,  0.0293,  0.0055,\n",
              "                      -0.0218, -0.0160,  0.0199, -0.0284,  0.0321,  0.0205,  0.0265, -0.0265,\n",
              "                      -0.0289,  0.0248, -0.0054,  0.0014,  0.0044, -0.0172, -0.0293, -0.0279,\n",
              "                       0.0291, -0.0171,  0.0225,  0.0233,  0.0333,  0.0025, -0.0274, -0.0004,\n",
              "                       0.0036, -0.0027, -0.0324, -0.0248,  0.0281,  0.0019, -0.0016,  0.0222,\n",
              "                      -0.0001, -0.0305, -0.0342,  0.0013, -0.0118,  0.0140, -0.0159, -0.0315,\n",
              "                      -0.0011,  0.0297,  0.0047, -0.0158,  0.0168,  0.0291,  0.0194,  0.0230,\n",
              "                      -0.0269, -0.0336, -0.0353,  0.0107, -0.0006, -0.0158, -0.0091, -0.0317,\n",
              "                      -0.0091, -0.0150, -0.0249,  0.0247,  0.0315, -0.0021,  0.0025, -0.0196,\n",
              "                       0.0344,  0.0181,  0.0199,  0.0151, -0.0183, -0.0026, -0.0035, -0.0206,\n",
              "                       0.0055,  0.0100,  0.0106,  0.0355, -0.0177, -0.0184, -0.0170,  0.0240,\n",
              "                      -0.0061, -0.0149, -0.0337, -0.0196,  0.0125,  0.0198, -0.0223,  0.0019,\n",
              "                       0.0232, -0.0294, -0.0052, -0.0016,  0.0048,  0.0334,  0.0330, -0.0281,\n",
              "                       0.0193, -0.0201, -0.0085,  0.0148,  0.0086, -0.0234, -0.0235,  0.0228,\n",
              "                      -0.0354,  0.0281, -0.0027, -0.0225, -0.0030, -0.0007, -0.0246, -0.0038,\n",
              "                      -0.0022, -0.0054, -0.0352,  0.0209,  0.0295,  0.0237, -0.0318, -0.0103,\n",
              "                       0.0001,  0.0122, -0.0337,  0.0118,  0.0077,  0.0039,  0.0212,  0.0326,\n",
              "                      -0.0182, -0.0123, -0.0287, -0.0196, -0.0336, -0.0331,  0.0277, -0.0235,\n",
              "                      -0.0052, -0.0242,  0.0342, -0.0287, -0.0152,  0.0334,  0.0099, -0.0182,\n",
              "                      -0.0008,  0.0122, -0.0143, -0.0129,  0.0277, -0.0184,  0.0268,  0.0125,\n",
              "                       0.0164, -0.0019, -0.0129,  0.0146, -0.0221, -0.0024,  0.0208,  0.0295,\n",
              "                      -0.0229,  0.0233,  0.0329,  0.0053, -0.0337, -0.0127,  0.0202, -0.0315,\n",
              "                      -0.0207, -0.0076, -0.0218, -0.0191,  0.0316, -0.0136,  0.0023, -0.0344,\n",
              "                       0.0297, -0.0323, -0.0329, -0.0342, -0.0150, -0.0257, -0.0340, -0.0176,\n",
              "                       0.0123,  0.0283, -0.0354, -0.0047,  0.0354,  0.0121, -0.0294, -0.0269,\n",
              "                      -0.0127, -0.0163,  0.0289, -0.0308,  0.0260, -0.0233, -0.0150, -0.0040,\n",
              "                      -0.0274,  0.0311, -0.0043,  0.0074,  0.0217,  0.0119,  0.0065, -0.0179,\n",
              "                       0.0222,  0.0204, -0.0156,  0.0092, -0.0210,  0.0320, -0.0320, -0.0137,\n",
              "                      -0.0130,  0.0312,  0.0155, -0.0278, -0.0264,  0.0164, -0.0314,  0.0333,\n",
              "                       0.0191, -0.0158, -0.0132,  0.0270, -0.0181,  0.0194, -0.0171,  0.0273,\n",
              "                      -0.0038, -0.0258,  0.0337, -0.0024, -0.0029,  0.0195,  0.0266, -0.0174,\n",
              "                       0.0084,  0.0259,  0.0107,  0.0304,  0.0170,  0.0149,  0.0123, -0.0168,\n",
              "                       0.0178,  0.0285,  0.0141,  0.0052, -0.0028,  0.0080,  0.0311, -0.0228,\n",
              "                      -0.0303,  0.0195,  0.0190,  0.0036,  0.0128,  0.0072, -0.0252, -0.0203,\n",
              "                      -0.0016, -0.0339, -0.0339,  0.0090, -0.0349,  0.0228,  0.0290, -0.0020,\n",
              "                       0.0070,  0.0117,  0.0106,  0.0050,  0.0137, -0.0102,  0.0095, -0.0274,\n",
              "                       0.0324, -0.0225,  0.0177,  0.0215, -0.0047, -0.0188, -0.0184, -0.0098,\n",
              "                      -0.0173, -0.0305, -0.0254,  0.0310, -0.0087,  0.0187, -0.0245,  0.0034,\n",
              "                      -0.0084,  0.0033, -0.0011, -0.0088,  0.0104,  0.0128, -0.0141,  0.0337,\n",
              "                       0.0333,  0.0067,  0.0017,  0.0162, -0.0204, -0.0281, -0.0029, -0.0060,\n",
              "                       0.0116, -0.0289,  0.0013, -0.0028, -0.0159, -0.0335, -0.0043, -0.0065,\n",
              "                      -0.0281,  0.0146,  0.0053, -0.0338,  0.0056,  0.0216, -0.0158, -0.0141,\n",
              "                       0.0176,  0.0333, -0.0257,  0.0199, -0.0294,  0.0143,  0.0061, -0.0064,\n",
              "                       0.0143, -0.0275, -0.0005, -0.0016, -0.0058, -0.0013, -0.0081,  0.0213,\n",
              "                       0.0235,  0.0234,  0.0337, -0.0228,  0.0272, -0.0168, -0.0024,  0.0131,\n",
              "                       0.0173,  0.0043,  0.0116,  0.0301,  0.0246, -0.0269, -0.0346, -0.0142,\n",
              "                       0.0265,  0.0354, -0.0119, -0.0055, -0.0269,  0.0298,  0.0085, -0.0069,\n",
              "                      -0.0191,  0.0037,  0.0158, -0.0023, -0.0145, -0.0081,  0.0060, -0.0128,\n",
              "                       0.0051,  0.0033, -0.0255,  0.0309, -0.0132, -0.0353, -0.0047, -0.0021,\n",
              "                      -0.0033,  0.0326, -0.0272,  0.0035, -0.0246,  0.0202, -0.0272,  0.0124,\n",
              "                       0.0159,  0.0330,  0.0345, -0.0237,  0.0065, -0.0327, -0.0252,  0.0126,\n",
              "                      -0.0264,  0.0042,  0.0194,  0.0201, -0.0166, -0.0099, -0.0307, -0.0281])),\n",
              "             ('layer_stack.4.weight',\n",
              "              tensor([[ 0.0130,  0.0001, -0.0294,  ...,  0.0424,  0.0229, -0.0054],\n",
              "                      [ 0.0291,  0.0172, -0.0392,  ...,  0.0187,  0.0266, -0.0342],\n",
              "                      [ 0.0241,  0.0293,  0.0360,  ...,  0.0318, -0.0267,  0.0119],\n",
              "                      ...,\n",
              "                      [-0.0188,  0.0396, -0.0010,  ..., -0.0034,  0.0321, -0.0251],\n",
              "                      [-0.0331,  0.0044,  0.0424,  ...,  0.0003,  0.0114,  0.0355],\n",
              "                      [-0.0174,  0.0277,  0.0003,  ...,  0.0224, -0.0342,  0.0117]])),\n",
              "             ('layer_stack.4.bias',\n",
              "              tensor([-0.0290, -0.0125, -0.0278, -0.0126, -0.0293, -0.0296, -0.0149, -0.0326,\n",
              "                      -0.0165, -0.0007, -0.0229, -0.0102, -0.0100,  0.0271, -0.0439, -0.0168,\n",
              "                      -0.0259, -0.0105, -0.0303, -0.0099,  0.0095, -0.0359, -0.0208, -0.0190,\n",
              "                       0.0339, -0.0050,  0.0375,  0.0281, -0.0091, -0.0092,  0.0208, -0.0073,\n",
              "                      -0.0232, -0.0402, -0.0186,  0.0063,  0.0221, -0.0271, -0.0282,  0.0007,\n",
              "                       0.0166, -0.0043, -0.0175, -0.0259,  0.0229, -0.0303, -0.0147, -0.0178,\n",
              "                       0.0230, -0.0108,  0.0067,  0.0374, -0.0158,  0.0396,  0.0229,  0.0250,\n",
              "                       0.0020,  0.0124,  0.0109, -0.0356,  0.0202,  0.0004,  0.0044, -0.0274,\n",
              "                       0.0311, -0.0287, -0.0411, -0.0022,  0.0045, -0.0128,  0.0401, -0.0399,\n",
              "                       0.0130, -0.0328, -0.0381, -0.0027,  0.0197, -0.0250, -0.0230, -0.0111,\n",
              "                      -0.0059,  0.0282, -0.0022,  0.0419,  0.0355, -0.0299,  0.0171,  0.0379,\n",
              "                       0.0419, -0.0257, -0.0215,  0.0361, -0.0273, -0.0280, -0.0002,  0.0360,\n",
              "                      -0.0067, -0.0021,  0.0138,  0.0270, -0.0153,  0.0188, -0.0224,  0.0094,\n",
              "                      -0.0083,  0.0074,  0.0119, -0.0418,  0.0358,  0.0353, -0.0303, -0.0260,\n",
              "                      -0.0420,  0.0252,  0.0373,  0.0032,  0.0039, -0.0193,  0.0348,  0.0253,\n",
              "                      -0.0307, -0.0433,  0.0254, -0.0405,  0.0372, -0.0321,  0.0330, -0.0037])),\n",
              "             ('layer_stack.6.weight',\n",
              "              tensor([[-0.0883,  0.0385,  0.0046,  ...,  0.0222,  0.0713, -0.0682],\n",
              "                      [ 0.0521,  0.0821, -0.0807,  ..., -0.0706, -0.0170,  0.0769],\n",
              "                      [-0.0091,  0.0416,  0.0718,  ...,  0.0465, -0.0694,  0.0544],\n",
              "                      ...,\n",
              "                      [-0.0247, -0.0415, -0.0496,  ..., -0.0464, -0.0499,  0.0253],\n",
              "                      [-0.0420, -0.0628,  0.0758,  ...,  0.0785,  0.0616, -0.0077],\n",
              "                      [ 0.0043, -0.0438,  0.0589,  ..., -0.0664, -0.0487,  0.0871]])),\n",
              "             ('layer_stack.6.bias',\n",
              "              tensor([-0.0010, -0.0569,  0.0128, -0.0239,  0.0620,  0.0540, -0.0067,  0.0067,\n",
              "                      -0.0272, -0.0155,  0.0188, -0.0868, -0.0428, -0.0713,  0.0104,  0.0135,\n",
              "                      -0.0868, -0.0576,  0.0860,  0.0106,  0.0410,  0.0471, -0.0842, -0.0741,\n",
              "                       0.0722, -0.0331,  0.0844, -0.0770, -0.0024, -0.0283, -0.0487, -0.0708])),\n",
              "             ('layer_stack.8.weight',\n",
              "              tensor([[ 0.1112,  0.1219, -0.0782, -0.0880,  0.0381,  0.0686,  0.0337, -0.1081,\n",
              "                       -0.1165, -0.1720,  0.0772, -0.0405,  0.1590, -0.1102,  0.1228,  0.0464,\n",
              "                        0.0478,  0.0447, -0.0533,  0.0151,  0.1454,  0.0990,  0.1498, -0.0289,\n",
              "                        0.0239,  0.1709,  0.1141, -0.1741,  0.0623,  0.1278, -0.1684, -0.0397],\n",
              "                      [-0.0560,  0.0278, -0.0327,  0.0566, -0.1010, -0.1289,  0.0208,  0.1256,\n",
              "                        0.0119,  0.1304, -0.1537,  0.1647, -0.1000,  0.0717, -0.0511,  0.1519,\n",
              "                        0.1225, -0.0218, -0.0852, -0.1277, -0.0582, -0.1651, -0.1525,  0.0404,\n",
              "                        0.1261, -0.0667, -0.1073,  0.0245, -0.1207, -0.0449, -0.0625,  0.0297],\n",
              "                      [ 0.0877,  0.0577, -0.0639, -0.0523, -0.0578,  0.1180,  0.1759, -0.0837,\n",
              "                        0.0917, -0.1462,  0.1407,  0.0826,  0.0423, -0.0890, -0.1258, -0.0445,\n",
              "                        0.0625, -0.0778, -0.0785, -0.0077, -0.1343, -0.0340, -0.0124,  0.1318,\n",
              "                       -0.1468, -0.1068, -0.0398,  0.1452, -0.1416, -0.0173,  0.0785, -0.1202],\n",
              "                      [-0.1270,  0.0949, -0.0177,  0.0844, -0.1456, -0.0196,  0.0029,  0.1275,\n",
              "                        0.0503,  0.0099,  0.1165, -0.1193,  0.1128,  0.1058,  0.1513,  0.0356,\n",
              "                        0.0033,  0.0104, -0.1351,  0.0589,  0.1412,  0.1637,  0.1345, -0.0274,\n",
              "                        0.1620, -0.1688, -0.0682, -0.0687,  0.0897, -0.0042, -0.1553,  0.0661],\n",
              "                      [-0.0078, -0.0963,  0.0635, -0.0952, -0.1531,  0.1734, -0.1380, -0.0265,\n",
              "                        0.0757,  0.0662, -0.0082,  0.0019, -0.1012,  0.1721, -0.1367, -0.0068,\n",
              "                        0.1407,  0.0044, -0.1675, -0.0379, -0.0656, -0.0762, -0.1001,  0.0903,\n",
              "                       -0.1621,  0.0930, -0.1616,  0.1304, -0.1370, -0.0345, -0.1162, -0.0415],\n",
              "                      [ 0.0384, -0.0567,  0.1642,  0.1081, -0.0928, -0.0689, -0.0425, -0.0162,\n",
              "                        0.0945,  0.1348, -0.1232, -0.1214,  0.0538,  0.1430,  0.0647,  0.1456,\n",
              "                        0.0600,  0.0906, -0.0780,  0.0392, -0.1765, -0.1293,  0.0625, -0.0675,\n",
              "                       -0.0974, -0.0040, -0.0503,  0.1559,  0.0882,  0.1682, -0.0677,  0.1437],\n",
              "                      [ 0.1456,  0.0447, -0.1210, -0.1519, -0.1552, -0.0915,  0.0930, -0.0302,\n",
              "                       -0.1164, -0.1035, -0.0548,  0.1607,  0.0016,  0.0109,  0.0450,  0.0636,\n",
              "                        0.1028, -0.1609,  0.0892, -0.0207,  0.1332, -0.0839, -0.1703,  0.0730,\n",
              "                       -0.0670,  0.0111,  0.0915,  0.1400,  0.1680, -0.1726, -0.1562, -0.1556],\n",
              "                      [-0.0343,  0.0595, -0.0680,  0.0726,  0.1689,  0.0306, -0.0699, -0.1170,\n",
              "                       -0.1393, -0.1177, -0.0182, -0.0238,  0.0439,  0.1039, -0.0639,  0.1723,\n",
              "                       -0.1623, -0.0456, -0.0955,  0.1272, -0.0483, -0.1409, -0.0311, -0.0061,\n",
              "                       -0.1303,  0.0002, -0.0291, -0.0825, -0.1303,  0.1622, -0.0147,  0.1130],\n",
              "                      [-0.1293, -0.0522,  0.1182, -0.0209,  0.0360,  0.1375,  0.0254, -0.1262,\n",
              "                       -0.1389,  0.1500,  0.1729,  0.0124,  0.0132,  0.1207, -0.1765,  0.1028,\n",
              "                        0.0006, -0.0311,  0.1569, -0.0959, -0.1028, -0.1740, -0.1051,  0.1474,\n",
              "                        0.1434, -0.1059,  0.1686, -0.0156, -0.1411,  0.1241,  0.0714, -0.1361],\n",
              "                      [-0.1121,  0.0945,  0.0773, -0.1709, -0.0327, -0.0040,  0.0292,  0.1265,\n",
              "                        0.0122, -0.1043,  0.1572, -0.0157, -0.0553,  0.1268, -0.1504, -0.1389,\n",
              "                       -0.1274,  0.1021, -0.1080,  0.1422,  0.0669,  0.1640, -0.0359,  0.0829,\n",
              "                        0.0439, -0.1152,  0.0678, -0.1681, -0.1588,  0.0946,  0.1215, -0.0229]])),\n",
              "             ('layer_stack.8.bias',\n",
              "              tensor([-0.0248, -0.0904, -0.1469, -0.1635,  0.1085, -0.1684, -0.0430, -0.0604,\n",
              "                      -0.0217, -0.1330]))])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "u6WbsiTjbP_W",
        "outputId": "24fdf82d-61b1-4d28-8b18-37c8fa5e39d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fashion_model(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=32, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=32, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_b_sample[0].shape"
      ],
      "metadata": {
        "id": "3hhBtAiiZsgw",
        "outputId": "ced41451-b114-4f6e-ce19-07d31987bf82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make inference/prediction and visualize the model\n",
        "with torch.inference_mode():\n",
        "  pred=model(x_train_b_sample[0])"
      ],
      "metadata": {
        "id": "O_aqHJKRZAcj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.sigmoid(pred).squeeze())"
      ],
      "metadata": {
        "id": "O3xR9zgVbhpU",
        "outputId": "fbe8c810-504c-44cd-9bbf-1ee7ae0ea0c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4979, 0.4723, 0.4612, 0.4553, 0.5165, 0.4544, 0.4912, 0.4841, 0.4993,\n",
              "        0.4648])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CREATE OPTIMIZER / LOSS_FUNC"
      ],
      "metadata": {
        "id": "VxS7K9TsgiSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create loss func\n",
        "\n",
        "#optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "EaAq8b2yehWZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRAINING / TESTING LOOP"
      ],
      "metadata": {
        "id": "6vBh6ZxMPsYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tips\n",
        "0. Loop throug the data\n",
        "1. set to training mode\n",
        "2. Forward pass\n",
        "3. Calculate the loss(pred to ground truth)\n",
        "4. optimizer zer grad\n",
        "5. loss backward .. back propogation\n",
        "6. optimizer step - use opt and adjust parameter ... grad desent\n"
      ],
      "metadata": {
        "id": "ntg6do8cclFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initiate trackers and hyper parameters\n",
        "epoch=100\n",
        "epochs=range(epoch)\n",
        "train_loss_track=[]\n",
        "test_loss_track=[]\n",
        "\n",
        "\n",
        "#training loop\n",
        "\n",
        "  ####testing part\n",
        " \n"
      ],
      "metadata": {
        "id": "UuHsExVJbq5E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EVALUATION OF THE MODEL"
      ],
      "metadata": {
        "id": "BNgX5AsNKXxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot / matrices\n",
        "\n"
      ],
      "metadata": {
        "id": "tCba4hBEeOa-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SAVING/LOADING"
      ],
      "metadata": {
        "id": "KwxZmgXUPJgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tips\n",
        "1.  torch.save() \n",
        "2.  torch.load()\n",
        "3.  toch.nn.Module.load_state_dict()"
      ],
      "metadata": {
        "id": "zW_QlscXPZsx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "se4kqYtmQwPX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "na5mRKb3fvDb"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}